{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (20,10)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('telcom_data.xlsx')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_per_user = df.groupby('MSISDN/Number').size().reset_index(name='xDR Session Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_per_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Session Duration Per Hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_duration = df.groupby('MSISDN/Number')['Dur. (ms)'].sum().reset_index(name='Total Duration (ms)')\n",
    "session_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_ul_total = df.groupby('MSISDN/Number')[['Total DL (Bytes)', 'Total UL (Bytes)']].sum().reset_index()\n",
    "dl_ul_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify application columns\n",
    "app_columns = [col for col in df.columns if any(app in col for app in [\n",
    "    'Youtube', 'Netflix', 'Gaming', 'Google', 'Email', 'Social Media', 'Other'\n",
    "])]\n",
    "\n",
    "# Aggregate per user\n",
    "app_usage = df.groupby('MSISDN/Number')[app_columns].sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all summaries step by step\n",
    "result = sessions_per_user \\\n",
    "    .merge(session_duration, on='MSISDN/Number') \\\n",
    "    .merge(dl_ul_total, on='MSISDN/Number') \\\n",
    "    .merge(app_usage, on='MSISDN/Number')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.head())  # Shows user-wise summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df.mean(numeric_only=True), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include=np.number).columns:\n",
    "    lower = df[col].quantile(0.01)\n",
    "    upper = df[col].quantile(0.99)\n",
    "    df[col] = np.clip(df[col], lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Metrics (mean, median, std, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_stats = df.describe().T[['mean', '50%', 'std', 'min', 'max']]\n",
    "basic_stats.rename(columns={'50%': 'median'}, inplace=True)\n",
    "print(basic_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Graphical Univariate Analysis (Dispersion Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispersion = df.select_dtypes(include=np.number).agg(['mean', 'std', 'var', 'min', 'max']).T\n",
    "print(dispersion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphical Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate Analysis – App vs Total Data (DL + UL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total_Data(Bytes)'] = df['Total DL (Bytes)'] + df['Total UL (Bytes)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_cols = [col for col in df.columns if 'DL (Bytes)' in col or 'UL (Bytes)' in col and any(x in col for x in ['Youtube', 'Netflix', 'Email', 'Google', 'Social Media', 'Gaming', 'Other'])]\n",
    "\n",
    "for col in app_cols:\n",
    "    if col != 'Total_Data(Bytes)':\n",
    "        sns.scatterplot(x=df[col], y=df['Total_Data(Bytes)'])\n",
    "        plt.title(f\"{col} vs Total Data\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable Transformation – User Segmentation by Decile of Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Decile'] = pd.qcut(df['Dur. (ms)'], 10, labels=False, duplicates='drop')\n",
    "\n",
    "# Now compute data usage per decile\n",
    "decile_analysis = df.groupby('Decile')['Total_Data(Bytes)'].sum().reset_index()\n",
    "print(decile_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Analysis – Application Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_related = [col for col in df.columns if any(x in col for x in ['Youtube', 'Netflix', 'Email', 'Google', 'Social Media', 'Gaming', 'Other'])]\n",
    "\n",
    "correlation_matrix = df[app_related].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation Matrix – Application Data\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df[app_related].fillna(0)\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "pca = PCA()\n",
    "pca_components = pca.fit_transform(X_scaled)\n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(explained_variance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(np.cumsum(explained_variance))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA - Explained Variance')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate Engagement Metrics per User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Aggregate required metrics per user\n",
    "df['Total_Traffic(Bytes)'] = df['Total DL (Bytes)'] + df['Total UL (Bytes)']\n",
    "\n",
    "user_metrics = df.groupby('MSISDN/Number').agg({\n",
    "    'Dur. (ms)': 'sum',\n",
    "    'Total_Traffic(Bytes)': 'sum',\n",
    "    'MSISDN/Number': 'count'  # session count = frequency\n",
    "}).rename(columns={'MSISDN/Number': 'Session Frequency',\n",
    "                   'Dur. (ms)': 'Total Duration',\n",
    "                   'Total_Traffic(Bytes)': 'Total Traffic'}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Report Top 10 Users per Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 by frequency\n",
    "print(user_metrics.nlargest(10, 'Session Frequency'))\n",
    "\n",
    "# Top 10 by duration\n",
    "print(user_metrics.nlargest(10, 'Total Duration'))\n",
    "\n",
    "# Top 10 by traffic\n",
    "print(user_metrics.nlargest(10, 'Total Traffic'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize Metrics & Apply K-Means (k=3)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Normalize\n",
    "scaler = MinMaxScaler()\n",
    "engagement_scaled = scaler.fit_transform(user_metrics[['Session Frequency', 'Total Duration', 'Total Traffic']])\n",
    "\n",
    "# Apply KMeans\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "user_metrics['Engagement Cluster'] = kmeans.fit_predict(engagement_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster-wise Stats (non-normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_stats = user_metrics.groupby('Engagement Cluster')[['Session Frequency', 'Total Duration', 'Total Traffic']].agg(['min', 'max', 'mean', 'sum'])\n",
    "print(cluster_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Traffic Per Application Per User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_cols = [col for col in df.columns if any(x in col for x in [\n",
    "    'Youtube', 'Netflix', 'Email', 'Google', 'Social Media', 'Gaming', 'Other'\n",
    "])]\n",
    "\n",
    "# Add total app traffic columns\n",
    "df['MSISDN/Number'] = df['MSISDN/Number'].astype(str)\n",
    "app_traffic = df.groupby('MSISDN/Number')[app_cols].sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 10 Most Engaged Users Per App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_users_per_app = {}\n",
    "for col in app_cols:\n",
    "    top_users_per_app[col] = app_traffic[['MSISDN/Number', col]].nlargest(10, col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 3 Most Used Applications – Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_total = df[app_cols].sum().sort_values(ascending=False).head(3)\n",
    "\n",
    "# Plot\n",
    "app_total.plot(kind='bar', title='Top 3 Most Used Applications', ylabel='Total Bytes')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize K Using Elbow Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow Method\n",
    "inertia = []\n",
    "K = range(1, 11)\n",
    "\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k, random_state=42)\n",
    "    km.fit(engagement_scaled)\n",
    "    inertia.append(km.inertia_)\n",
    "\n",
    "# Plot elbow\n",
    "plt.plot(K, inertia, marker='o')\n",
    "plt.title(\"Elbow Method - Optimal k\")\n",
    "plt.xlabel(\"Number of clusters (k)\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    'TCP DL Retrans. Vol (Bytes)', 'TCP UL Retrans. Vol (Bytes)',\n",
    "    'Avg RTT DL (ms)', 'Avg RTT UL (ms)',\n",
    "    'Avg Bearer TP DL (kbps)', 'Avg Bearer TP UL (kbps)'\n",
    "]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "df['Handset Type'].fillna(df['Handset Type'].mode()[0], inplace=True)\n",
    "\n",
    "# Treat outliers (clip to 1st and 99th percentile)\n",
    "for col in numeric_cols:\n",
    "    lower = df[col].quantile(0.01)\n",
    "    upper = df[col].quantile(0.99)\n",
    "    df[col] = np.clip(df[col], lower, upper)\n",
    "\n",
    "# Create aggregate experience metrics\n",
    "df['Avg_TCP_Retrans'] = (df['TCP DL Retrans. Vol (Bytes)'] + df['TCP UL Retrans. Vol (Bytes)']) / 2\n",
    "df['Avg_RTT'] = (df['Avg RTT DL (ms)'] + df['Avg RTT UL (ms)']) / 2\n",
    "df['Avg_Throughput'] = (df['Avg Bearer TP DL (kbps)'] + df['Avg Bearer TP UL (kbps)']) / 2\n",
    "\n",
    "# Aggregate per user\n",
    "user_experience = df.groupby('MSISDN/Number').agg({\n",
    "    'Avg_TCP_Retrans': 'mean',\n",
    "    'Avg_RTT': 'mean',\n",
    "    'Avg_Throughput': 'mean',\n",
    "    'Handset Type': lambda x: x.mode()[0]  # most frequent handset type\n",
    "}).reset_index()\n",
    "\n",
    "print(user_experience.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top, Bottom, and Most Frequent Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. TCP values\n",
    "tcp_values = df['Avg_TCP_Retrans']\n",
    "print(\"Top 10 TCP retransmission values:\\n\", tcp_values.nlargest(10))\n",
    "print(\"Bottom 10 TCP retransmission values:\\n\", tcp_values.nsmallest(10))\n",
    "print(\"Most frequent TCP retransmission values:\\n\", tcp_values.value_counts().head(10))\n",
    "\n",
    "# b. RTT values\n",
    "rtt_values = df['Avg_RTT']\n",
    "print(\"Top 10 RTT values:\\n\", rtt_values.nlargest(10))\n",
    "print(\"Bottom 10 RTT values:\\n\", rtt_values.nsmallest(10))\n",
    "print(\"Most frequent RTT values:\\n\", rtt_values.value_counts().head(10))\n",
    "\n",
    "# c. Throughput values\n",
    "tp_values = df['Avg_Throughput']\n",
    "print(\"Top 10 Throughput values:\\n\", tp_values.nlargest(10))\n",
    "print(\"Bottom 10 Throughput values:\\n\", tp_values.nsmallest(10))\n",
    "print(\"Most frequent Throughput values:\\n\", tp_values.value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution by Handset Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "throughput_by_handset = user_experience.groupby('Handset Type')['Avg_Throughput'].mean().sort_values(ascending=False)\n",
    "print(throughput_by_handset)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "throughput_by_handset.head(10).plot(kind='bar')\n",
    "plt.title(\"Avg Throughput per Handset Type (Top 10)\")\n",
    "plt.ylabel(\"Throughput (kbps)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TCP retransmission per Handset Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcp_by_handset = user_experience.groupby('Handset Type')['Avg_TCP_Retrans'].mean().sort_values(ascending=False)\n",
    "print(tcp_by_handset)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "tcp_by_handset.head(10).plot(kind='bar', color='orange')\n",
    "plt.title(\"Avg TCP Retransmission per Handset Type (Top 10)\")\n",
    "plt.ylabel(\"TCP Retransmission (Bytes)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KMeans Clustering on Experience Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_features = user_experience[['Avg_TCP_Retrans', 'Avg_RTT', 'Avg_Throughput']]\n",
    "scaler = MinMaxScaler()\n",
    "experience_scaled = scaler.fit_transform(experience_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "user_experience['Experience Cluster'] = kmeans.fit_predict(experience_scaled)\n",
    "\n",
    "# Cluster Summary\n",
    "cluster_summary = user_experience.groupby('Experience Cluster')[['Avg_TCP_Retrans', 'Avg_RTT', 'Avg_Throughput']].mean()\n",
    "print(cluster_summary)\n",
    "\n",
    "# Visualizing cluster distribution\n",
    "sns.pairplot(user_experience, hue='Experience Cluster', vars=['Avg_TCP_Retrans', 'Avg_RTT', 'Avg_Throughput'])\n",
    "plt.suptitle(\"User Experience Clusters\", y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Engagement & Experience Scores (Euclidean Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# Engagement features and clustering (from Task 2)\n",
    "engagement_features = ['Session Frequency', 'Total Duration', 'Total Traffic']\n",
    "engagement_data = user_metrics[engagement_features]\n",
    "least_engaged_center = engagement_data[user_metrics['Engagement Cluster'] == user_metrics['Engagement Cluster'].value_counts().idxmin()].mean().values\n",
    "\n",
    "# Experience features and clustering (from Task 3)\n",
    "experience_features = ['Avg_TCP_Retrans', 'Avg_RTT', 'Avg_Throughput']\n",
    "experience_data = user_experience[experience_features]\n",
    "worst_experience_center = experience_data[user_experience['Experience Cluster'] == user_experience['Experience Cluster'].value_counts().idxmax()].mean().values\n",
    "\n",
    "# Compute distances (scores)\n",
    "user_metrics['Engagement Score'] = euclidean_distances(engagement_data, [least_engaged_center]).flatten()\n",
    "user_experience['Experience Score'] = euclidean_distances(experience_data, [worst_experience_center]).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Satisfaction Score & Top 10 Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure MSISDN is string in both DataFrames\n",
    "user_metrics['MSISDN/Number'] = user_metrics['MSISDN/Number'].astype(str)\n",
    "user_experience['MSISDN/Number'] = user_experience['MSISDN/Number'].astype(str)\n",
    "\n",
    "# Now safe to merge\n",
    "final_df = pd.merge(\n",
    "    user_metrics[['MSISDN/Number', 'Engagement Score']],\n",
    "    user_experience[['MSISDN/Number', 'Experience Score']],\n",
    "    on='MSISDN/Number'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Satisfaction Score'] = final_df[['Engagement Score', 'Experience Score']].mean(axis=1)\n",
    "\n",
    "# Top 10 satisfied users\n",
    "top_satisfied = final_df.sort_values(by='Satisfaction Score', ascending=False).head(10)\n",
    "print(top_satisfied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression Model to Predict Satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Use engagement and experience scores to predict satisfaction\n",
    "X = final_df[['Engagement Score', 'Experience Score']]\n",
    "y = final_df['Satisfaction Score']\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 Score:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KMeans on Engagement + Experience Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans_satisfaction = KMeans(n_clusters=2, random_state=42)\n",
    "final_df['Satisfaction Cluster'] = kmeans_satisfaction.fit_predict(final_df[['Engagement Score', 'Experience Score']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Aggregation of Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_avg = final_df.groupby('Satisfaction Cluster')[['Satisfaction Score', 'Experience Score']].mean()\n",
    "print(cluster_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "\n",
    "conn = pyodbc.connect(\n",
    "    r'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "    r'SERVER=DESKTOP-SFKESGV\\SQLEXPRESS;'  # Change to your server\n",
    "    r'DATABASE=telecom_data;'             # Change to your DB name\n",
    "    r'Trusted_Connection=yes;'\n",
    ")\n",
    "\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"\"\"\n",
    "IF OBJECT_ID('dbo.satisfaction_analysis', 'U') IS NULL\n",
    "BEGIN\n",
    "    CREATE TABLE dbo.satisfaction_analysis (\n",
    "        msisdn VARCHAR(255) PRIMARY KEY,\n",
    "        engagement_score FLOAT,\n",
    "        experience_score FLOAT,\n",
    "        satisfaction_score FLOAT,\n",
    "        satisfaction_cluster INT\n",
    "    )\n",
    "END\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for _, row in final_df.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        MERGE INTO dbo.satisfaction_analysis AS target\n",
    "        USING (SELECT ? AS msisdn) AS source\n",
    "        ON target.msisdn = source.msisdn\n",
    "        WHEN MATCHED THEN\n",
    "            UPDATE SET engagement_score = ?, experience_score = ?, satisfaction_score = ?, satisfaction_cluster = ?\n",
    "        WHEN NOT MATCHED THEN\n",
    "            INSERT (msisdn, engagement_score, experience_score, satisfaction_score, satisfaction_cluster)\n",
    "            VALUES (?, ?, ?, ?, ?);\n",
    "    \"\"\", (\n",
    "        row['MSISDN/Number'],\n",
    "        row['Engagement Score'], row['Experience Score'], row['Satisfaction Score'], row['Satisfaction Cluster'],\n",
    "        row['MSISDN/Number'], row['Engagement Score'], row['Experience Score'], row['Satisfaction Score'], row['Satisfaction Cluster']\n",
    "    ))\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Deployment & Tracking (Lightweight MLOps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import time\n",
    "\n",
    "mlflow.set_experiment(\"satisfaction_model_tracking\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    start_time = time.time()\n",
    "\n",
    "    mlflow.log_param(\"model_type\", \"LinearRegression\")\n",
    "    mlflow.log_param(\"train_size\", len(X_train))\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"r2_score\", r2)\n",
    "    \n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    mlflow.log_metric(\"training_duration\", end_time - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
